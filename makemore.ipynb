{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac25620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b529f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaefee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dtype = torch.float32\n",
    "\n",
    "torch.set_default_dtype(default_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae294a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.txt', 'r') as file:\n",
    "    words = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b15c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words):\n",
    "    for w in words:\n",
    "        chs = ['.'] + list(w) + ['.']\n",
    "        for c1, c2 in zip(chs, chs[1:]):\n",
    "            yield c1, c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf054b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted(Counter(sorted(bigrams(words))).items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c252f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "n = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((n, n), dtype=torch.int32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db74cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c1, c2 in bigrams(words):\n",
    "    i1 = stoi[c1]\n",
    "    i2 = stoi[c2]\n",
    "    N[i1, i2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 16), dpi=200)\n",
    "ax.imshow(N, cmap='Blues')\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        ax.text(j, i, chstr, ha=\"center\", va=\"bottom\", color=\"gray\")\n",
    "        ax.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color=\"gray\")\n",
    "ax.axis(\"off\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = N[0].float()\n",
    "p /= p.sum()\n",
    "g = torch.Generator(device='cpu').manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = N.float()\n",
    "P /= P.sum(axis=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949abcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeone():\n",
    "    ix = 0\n",
    "    s = ''\n",
    "    while True:\n",
    "        #p = N[ix].float()\n",
    "        #p /= p.sum()\n",
    "        p = P[ix]\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        if ix == 0:\n",
    "            break\n",
    "        s += itos[ix]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282df351",
   "metadata": {},
   "source": [
    "Now want to evaluate the model. The idea is to calculate the likelihood of the dataset given the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = 0\n",
    "n = 0\n",
    "bestword = ''\n",
    "bestll = -float('inf')\n",
    "for word in words:\n",
    "    chs = ['.'] + list(word) + ['.']\n",
    "    wordll = 0\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        i1, i2 = stoi[c1], stoi[c2]\n",
    "        lp = torch.log(P[i1, i2])\n",
    "        ll += lp\n",
    "        wordll += lp\n",
    "        n += 1\n",
    "    if wordll > bestll:\n",
    "        bestll = wordll\n",
    "        bestword = word\n",
    "print(bestword, bestll)\n",
    "nnll = -ll/n\n",
    "print(nnll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c37f0",
   "metadata": {},
   "source": [
    "Create a dataset. We do this by turning character indices into one hot vector. The first character in a bigram is an $x$, the second character is a $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1696a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for word in words:\n",
    "    chs = ['.'] + list(word) + ['.']\n",
    "    for c1, c2 in zip(chs, chs[1:]):\n",
    "        i1 = stoi[c1]\n",
    "        i2 = stoi[c2]\n",
    "        xs.append(i1)\n",
    "        ys.append(i2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, 27).to(default_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cc22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator(device='cuda').manual_seed(2147483647)\n",
    "W = torch.randn(27, 27, generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can jump straight to a perfect set of weights\n",
    "# W = torch.log(P+0.0000000001).cuda(); W.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dee18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "print(f\"{'epoch':>6} {'loss':>10} {'time,s':>7}\")\n",
    "for i in range(100000):\n",
    "    logits = xenc @ W # log-counts\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(len(xs)), ys].log().mean()# + 20*(W**2).mean()\n",
    "    if (i+1)%1000 == 1:\n",
    "        tt = time.time()\n",
    "        print(f\"{i+1:6} {loss.data.item():10.5f} {tt-t:>7.2f}\")\n",
    "        t = tt\n",
    "\n",
    "    W.grad = None # zero out the gradients\n",
    "    loss.backward()\n",
    "    W.data += -1*W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e25d984",
   "metadata": {},
   "source": [
    "sample from the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6632fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d525ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ''\n",
    "while True:\n",
    "    xenc = F.one_hot(torch.tensor([i]), 27).float()\n",
    "\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "\n",
    "    i = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "\n",
    "    if i == 0:\n",
    "        break\n",
    "    \n",
    "    w += itos[i]\n",
    "print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
